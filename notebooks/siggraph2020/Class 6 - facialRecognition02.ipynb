{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PiIDDU_iVVsG"
   },
   "outputs": [],
   "source": [
    "#%tensorflow_version 1.x\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O750irw4XFao"
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4EiuYXAebGg"
   },
   "outputs": [],
   "source": [
    "import mtcnn\n",
    "mtcnn_model = mtcnn.MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hKe2F9zaDbu"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cG6K81z1ynv"
   },
   "outputs": [],
   "source": [
    "facenet_model_path = '/content/drive/My Drive/00AA-SIGG/SIGGRAPH Now_Machine Learning Webinar/faces/facenet_keras.h5'\n",
    "facenet_model = tf.keras.models.load_model(facenet_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrTue4W4Hn1X"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "!curl -o pixney_faces.jpeg https://i.pinimg.com/originals/cf/04/14/cf0414f971aa50c87140ed49223da33b.jpg\n",
    "disneypixarfaces = cv2.imread('pixney_faces.jpeg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrwYq-Qt1sB4"
   },
   "outputs": [],
   "source": [
    "face_path = '/content/drive/My Drive/00AA-SIGG/SIGGRAPH Now_Machine Learning Webinar/faces/'\n",
    "names_faces = {\n",
    "    # name        :  face \n",
    "    'RajeshSharma'   : 'Rajesh1.jpg',\n",
    "    'AlbertoMartin'  : 'AlbertoMartin1.jpg',\n",
    "    'Donovan'        : 'Donovan1.jpg',\n",
    "    'Gabriel'        : 'GabrielZ1.jpg',\n",
    "    'Gerrit'         : 'Gerrit1.jpg',\n",
    "    'JesusH'         : 'JesusH1.jpg',\n",
    "    'JonathanM'      : 'JonathanM1.jpg',\n",
    "    'LouH'           : 'LouH1.jpg',\n",
    "    'MartinA'        : 'MartinA1.jpg',\n",
    "    'Randi'          : 'Randi1.jpg',\n",
    "    'ThanhP'         : 'ThanhP1.jpg',\n",
    "}\n",
    "print(names_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XjIzK2V_R6j"
   },
   "outputs": [],
   "source": [
    "# show the images (these will be our ground truth)\n",
    "for name, face in names_faces.items(): \n",
    "    # replace file names with actual images in the dictionary\n",
    "    img = cv2.imread(face_path+face)\n",
    "    # cv2 by default stores images in BGR format, store in RGB\n",
    "    names_faces[name] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    print('\\n', name)\n",
    "    cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIBLz66wMntb"
   },
   "outputs": [],
   "source": [
    "def whiten_image(img):\n",
    "  img = img/255.0\n",
    "  axis = (0, 1, 2)\n",
    "  size = img.size\n",
    "  mean = np.mean(img, axis=axis, keepdims=True)\n",
    "  std = np.std(img, axis=axis, keepdims=True)\n",
    "  std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "  whitened_image = (img-mean)/std\n",
    "  return whitened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpOtPHe6jyn4"
   },
   "outputs": [],
   "source": [
    "def encode_face(img, x, y, w, h):\n",
    "  #only the face part\n",
    "  face_only = img[y:y+h, x:x+w, :]\n",
    "  # resize to 160x160 (without stretching)\n",
    "  face_only = skimage.transform.resize(face_only,(160, 160), mode='reflect')\n",
    "  # normalize\n",
    "  face_only = whiten_image(face_only)\n",
    "  # find encoding\n",
    "  encoding = facenet_model.predict(np.expand_dims(face_only, 0))\n",
    "  return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbVW9JIxFySu"
   },
   "outputs": [],
   "source": [
    "def encode_known_faces(face_dict):\n",
    "    for name, face in face_dict.items():\n",
    "        detected_faces = mtcnn_model.detect_faces(face)\n",
    "        # extract details of the face\n",
    "        for i in range(0, len(detected_faces)):\n",
    "            x, y, w, h = detected_faces[i]['box']\n",
    "            encoding = encode_face(face, x, y, w, h)\n",
    "            # store it away\n",
    "            face_dict[name] = encoding \n",
    "            #print(name, encoding)   \n",
    "            break # assume only one face per image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o7eij_5BmQqr"
   },
   "outputs": [],
   "source": [
    "def find_closest_face(encoding):\n",
    "  distances = []\n",
    "  for name, face in names_faces.items():\n",
    "    dist = np.linalg.norm(encoding-face)\n",
    "    distances.append(dist)\n",
    "  min_distance = np.min(distances)\n",
    "  min_distance_name = list(names_faces)[np.argmin(distances)]\n",
    "  return min_distance, min_distance_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBxZ_E2KImA2"
   },
   "outputs": [],
   "source": [
    "def recognize_faces(new_img):\n",
    "  faces = mtcnn_model.detect_faces(new_img)\n",
    "  for i in range(0, len(faces)):\n",
    "      x, y, w, h = faces[i]['box']\n",
    "      # compute encoding\n",
    "      encoding = encode_face(new_img, x, y, w, h)\n",
    "      # find the face with minimum encoding distance from this one\n",
    "      dist, name = find_closest_face(encoding)\n",
    "      if (dist < 11):\n",
    "          print(dist, name)\n",
    "          # draw rectangle and name\n",
    "          cv2.rectangle(new_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "          cv2.putText(new_img, name, (x, y-3), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.75, (255, 0, 0), 2)\n",
    "  return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFghn3wlQNoH"
   },
   "outputs": [],
   "source": [
    "encode_known_faces(names_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJaQ9P_lndGw"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(face_path+'All.jpg')\n",
    "cv2_imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3Kb-Qj-lJV5"
   },
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "final_img = recognize_faces(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3xf6NBdlAvK"
   },
   "outputs": [],
   "source": [
    "cv2_imshow(final_img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9euBMf60JOpo"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('sample.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "facialRecognition02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
