{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facialRecognition02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiIDDU_iVVsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import skimage.transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O750irw4XFao",
        "colab": {}
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4EiuYXAebGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mtcnn\n",
        "mtcnn_model = mtcnn.MTCNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hKe2F9zaDbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cG6K81z1ynv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facenet_model_path = '/content/drive/My Drive/00AA-SIGG/SIGGRAPH Now_Machine Learning Webinar/faces/facenet_keras.h5'\n",
        "facenet_model = tf.keras.models.load_model(facenet_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrTue4W4Hn1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "!curl -o pixney_faces.jpeg https://i.pinimg.com/originals/cf/04/14/cf0414f971aa50c87140ed49223da33b.jpg\n",
        "disneypixarfaces = cv2.imread('pixney_faces.jpeg', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrwYq-Qt1sB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_path = '/content/drive/My Drive/00AA-SIGG/SIGGRAPH Now_Machine Learning Webinar/faces/'\n",
        "names_faces = {\n",
        "    # name        :  face \n",
        "    'RajeshSharma'   : 'Rajesh1.jpg',\n",
        "    'AlbertoMartin'  : 'AlbertoMartin1.jpg',\n",
        "    'Donovan'        : 'Donovan1.jpg',\n",
        "    'Gabriel'        : 'GabrielZ1.jpg',\n",
        "    'Gerrit'         : 'Gerrit1.jpg',\n",
        "    'JesusH'         : 'JesusH1.jpg',\n",
        "    'JonathanM'      : 'JonathanM1.jpg',\n",
        "    'LouH'           : 'LouH1.jpg',\n",
        "    'MartinA'        : 'MartinA1.jpg',\n",
        "    'Randi'          : 'Randi1.jpg',\n",
        "    'ThanhP'         : 'ThanhP1.jpg',\n",
        "}\n",
        "print(names_faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XjIzK2V_R6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show the images (these will be our ground truth)\n",
        "for name, face in names_faces.items(): \n",
        "    # replace file names with actual images in the dictionary\n",
        "    img = cv2.imread(face_path+face)\n",
        "    # cv2 by default stores images in BGR format, store in RGB\n",
        "    names_faces[name] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    print('\\n', name)\n",
        "    cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIBLz66wMntb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def whiten_image(img):\n",
        "  img = img/255.0\n",
        "  axis = (0, 1, 2)\n",
        "  size = img.size\n",
        "  mean = np.mean(img, axis=axis, keepdims=True)\n",
        "  std = np.std(img, axis=axis, keepdims=True)\n",
        "  std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
        "  whitened_image = (img-mean)/std\n",
        "  return whitened_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpOtPHe6jyn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_face(img, x, y, w, h):\n",
        "  #only the face part\n",
        "  face_only = img[y:y+h, x:x+w, :]\n",
        "  # resize to 160x160 (without stretching)\n",
        "  face_only = skimage.transform.resize(face_only,(160, 160), mode='reflect')\n",
        "  # normalize\n",
        "  face_only = whiten_image(face_only)\n",
        "  # find encoding\n",
        "  encoding = facenet_model.predict(np.expand_dims(face_only, 0))\n",
        "  return encoding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbVW9JIxFySu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_known_faces(face_dict):\n",
        "    for name, face in face_dict.items():\n",
        "        detected_faces = mtcnn_model.detect_faces(face)\n",
        "        # extract details of the face\n",
        "        for i in range(0, len(detected_faces)):\n",
        "            x, y, w, h = detected_faces[i]['box']\n",
        "            encoding = encode_face(face, x, y, w, h)\n",
        "            # store it away\n",
        "            face_dict[name] = encoding \n",
        "            #print(name, encoding)   \n",
        "            break # assume only one face per image   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7eij_5BmQqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_closest_face(encoding):\n",
        "  distances = []\n",
        "  for name, face in names_faces.items():\n",
        "    dist = np.linalg.norm(encoding-face)\n",
        "    distances.append(dist)\n",
        "  min_distance = np.min(distances)\n",
        "  min_distance_name = list(names_faces)[np.argmin(distances)]\n",
        "  return min_distance, min_distance_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBxZ_E2KImA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recognize_faces(new_img):\n",
        "  faces = mtcnn_model.detect_faces(new_img)\n",
        "  for i in range(0, len(faces)):\n",
        "      x, y, w, h = faces[i]['box']\n",
        "      # compute encoding\n",
        "      encoding = encode_face(new_img, x, y, w, h)\n",
        "      # find the face with minimum encoding distance from this one\n",
        "      dist, name = find_closest_face(encoding)\n",
        "      if (dist < 11):\n",
        "          print(dist, name)\n",
        "          # draw rectangle and name\n",
        "          cv2.rectangle(new_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "          cv2.putText(new_img, name, (x, y-3), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.75, (255, 0, 0), 2)\n",
        "  return new_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFghn3wlQNoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_known_faces(names_faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kJaQ9P_lndGw",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(face_path+'All.jpg')\n",
        "cv2_imshow(img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Kb-Qj-lJV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "final_img = recognize_faces(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3xf6NBdlAvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(final_img[:,:,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9euBMf60JOpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('sample.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}